# DocMind â€” AI Research Agent Platform

DocMind is a full-stack AI-powered research agent platform designed for CS students who accumulate lecture slides, research papers, project documents, and course notes across multiple classes but struggle to extract useful information from them quickly. Users upload documents to build a private knowledge base, then query it via text and image inputs through an intelligent LangGraph agent that orchestrates retrieval, web search, and code execution.

## ğŸš€ Key Features

- **Document Processing Pipeline**: Upload PDFs, Markdown, and TXT files. Async processing extracts text, chunks, and generates vector embeddings automatically.
- **RAG Query Engine**: Hybrid search (BM25 + Semantic) combined with LangGraph provider-agnostic agents (supports Gemini, OpenAI, Qwen) to generate grounded responses with citations.
- **Multi-Modal Support**: Leverages Gemini 2.5 Flash native vision capabilities to analyze whiteboard photos and diagrams as part of the RAG pipeline.
- **Agentic Workflow**: Intelligent tool selection, dynamically routing between Knowledge Base Retrieval, Web Search fallbacks, and Code Execution.
- **Multiple Entry Points**: Accessible via a Next.js Web UI, an MCP Server (for Cursor/Claude integration), and Slack (via n8n workflows).
- **Secure & Private**: Powered by Supabase Auth and Row Level Security (RLS) to ensure per-user data isolation.

## ğŸ› ï¸ Tech Stack

### Backend
- **Framework**: Python FastAPI
- **Agent Orchestration**: LangGraph + LangChain
- **Database & Storage**: Supabase (PostgreSQL + pgvector + Storage)
- **Task Queue**: Celery + Redis
- **Evaluation**: RAGAS

### Frontend
- **Framework**: Next.js 14+ (App Router)
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **Streaming**: Server-Sent Events (SSE)

## ğŸ“ Project Structure

```text
AI-Research-Agent-Platform/
â”œâ”€â”€ backend/               # FastAPI application, LangGraph agent, and Celery workers
â”œâ”€â”€ frontend/              # Next.js web interface
â”œâ”€â”€ mcp_server/            # Model Context Protocol server for AI IDE/client integration
â”œâ”€â”€ docker-compose.yml     # Production services orchestration
â”œâ”€â”€ docker-compose.dev.yml # Local development orchestration with hot-reloading
â””â”€â”€ .agents/rules.md       # Project conventions and AI-assistant guardrails
```

## ğŸ’» Getting Started (Local Development)

### 1. Prerequisites
- Docker & Docker Compose
- Node.js 20+
- Python 3.11+ (We use `uv` for ultra-fast dependency management: `curl -LsSf https://astral.sh/uv/install.sh | sh`)
- Supabase Project (Get your keys from the dashboard)
- Google Gemini API Key (or OpenAI/Qwen depending on configuration)

### 2. Environment Setup

Copy the environment templates and fill in your keys:

```bash
# Backend (.env)
cp backend/.env.example backend/.env

# Frontend (.env)
cp frontend/.env.example frontend/.env.local
```

### 3. Run the Backend (Docker or Local)

#### Option A: Docker Compose (Easiest)
Start the FastAPI backend, Celery worker, and Redis queue using Docker Compose:

```bash
docker compose -f docker-compose.dev.yml up --build
```
The API will be available at `http://localhost:8000`.

#### Option B: Local Development (Using `uv`)
Navigate to the backend directory, sync dependencies, and start the development server:
```bash
cd backend
uv sync --all-extras
uv run uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### 4. Run the Frontend (Next.js)

In a new terminal, navigate to the frontend directory, install dependencies, and start the Next.js development server:

```bash
cd frontend
npm install
npm run dev
```

The app will be available at `http://localhost:3000`.

## ğŸ§ª Evaluation

DocMind uses the RAGAS framework to quantitatively evaluate RAG pipeline quality. A benchmark set of 30 questions with ground-truth answers ensures we meet our target metrics:
- Faithfulness â‰¥ 0.85
- Answer Relevancy â‰¥ 0.80
- Context Precision â‰¥ 0.75
- Context Recall â‰¥ 0.70

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.
